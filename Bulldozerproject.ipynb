{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuoL7Lzu0fxN10yScBOZAA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engogola/BULLDOZERPROJECT-UISNG-ML/blob/main/Bulldozerproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt-Dk3FAwuX6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hilJMflLbwTq"
      },
      "source": [
        "!wget https://github.com/mrdbourke/zero-to-mastery-ml/raw/master/data/bluebook-for-bulldozers.zip # download files from GitHub as zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'bluebook-for-bulldozers.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('.') # extract all data into current working directory\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we are going to go an example of machine learning learning project with the goal of predicting the sale price of bulldozers.\n",
        "##1. Problem defination\n",
        "> How well can we predict the future sale price of a bulldozer , given its characteristics and previous examples of how much similar bulldozers have been sold for?\n",
        "##2. Data\n",
        "The data is downloaded from the kaggle bluebooks for kaggle bulldozers competiton.\n",
        "The link to the data is ; https://github.com/mrdbourke/zero-to-mastery-ml/raw/master/data/bluebook-for-bulldozers.zip\n",
        "##3. Evaluation\n",
        "The evaluation metric for this competiton is the RMSLE(root mean  square log error) between the actual and predicted prices.\n",
        "note:The goal for most regression evaluation metrics is to minimize the error,i.e our goal in this project will be to build a model that minimises RMSLE.\n",
        "##4. Features\n",
        "For this competition, you are predicting the sale price of bulldozers sold at auctions.\n",
        "\n",
        "The data for this competition is split into three parts:\n",
        "\n",
        "Train.csv is the training set, which contains data through the end of 2011.\n",
        "Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
        "Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
        "The key fields are in train.csv are:\n",
        "\n",
        "SalesID: the uniue identifier of the sale\n",
        "MachineID: the unique identifier of a machine.  A machine can be sold multiple times\n",
        "saleprice: what the machine sold for at auction (only"
      ],
      "metadata": {
        "id": "VafuOXiiyzH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the sale prices of Bulldozers using machine learning\n"
      ],
      "metadata": {
        "id": "b90W571rynqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "\n",
        "#import training and validation sets\n",
        "df = pd.read_csv(\"/content/bluebook-for-bulldozers/TrainAndValid.csv\" ,low_memory=False,parse_dates=[\"saledate\"])\n",
        "df.info()\n",
        "df.saledate[:1000]\n",
        "#make a copy\n",
        "df_tmp=df.copy()\n"
      ],
      "metadata": {
        "id": "DWPp88_wyL2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modelling"
      ],
      "metadata": {
        "id": "FihMYL2FYMPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets build a machine learning model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model= RandomForestRegressor(n_jobs=-1,random_state=42)\n",
        "model.fit(df_tmp.drop(\"SalePrice\",axis=1),df_tmp[\"SalePrice\"])"
      ],
      "metadata": {
        "id": "vr_5IdWJYP9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert strings to categories\n",
        "pandas.api.types.is_string_dtype(df_tmp[\"UsageBand\"])\n",
        "#find the columns that contains strings\n",
        "for label, content in df_tmp.items():\n",
        "  if pd.api.types.is_string_dtype(content):\n",
        "    print(label)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1fMf6D6xASkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EjboNjBVCTRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put models in a dictionary\n",
        "!pip install scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "models ={\"Logistic Regression\" : LogisticRegression(),\"KNN\" :KNeighborsClassifier(),\"Random Forest\" :RandomForestClassifier()}\n",
        "# create a function to fit and score models\n",
        "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Fits models to the training set and evaluates them on the test set\n",
        "\n",
        "    Args:\n",
        "        models: a dict of models to fit and score\n",
        "        X_train: the training data(no labels)\n",
        "        X_test: training data(no labels)\n",
        "        y_train: the training labels\n",
        "        y_test: test label_ranking_loss\n",
        "        \"\"\"\n",
        "\n",
        "#set random seed\n",
        "np.random.seed(42)\n",
        "#make a dictionary to keep model scores\n",
        "model_scores = {}\n",
        "#loop thru' models\n",
        "for name,model in models.items():\n",
        "  #fit the model into the data\n",
        "  model.fit(X_train,y_train)\n",
        "  #evaluate the model and append its scoreto model scores\n",
        "  model_scores[name]=model.score('X_test,y_test')\n",
        "return model_scores\n",
        "model_scores = fit_and_score(models,X_train, X_test,y_train)\n",
        "print(models_scores)"
      ],
      "metadata": {
        "id": "6ZKrdnmxCTSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put models in a dictionary\n",
        "!pip install scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "models ={\"Logistic Regression\" : LogisticRegression(),\"KNN\" :KNeighborsClassifier(),\"Random Forest\" :RandomForestRegressor()}\n",
        "# create a function to fit and score models\n",
        "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Fits models to the training set and evaluates them on the test set\n",
        "\n",
        "    Args:\n",
        "        models: a dict of models to fit and score\n",
        "        X_train: the training data(no labels)\n",
        "        X_test: training data(no labels)\n",
        "        y_train: the training labels\n",
        "        y_test: test label_ranking_loss\n",
        "        \"\"\"\n",
        "\n",
        "#set random seed\n",
        "np.random.seed(42)\n",
        "#make a dictionary to keep model scores\n",
        "model_scores = {}\n",
        "#loop thru' models\n",
        "for name,model in models.items():\n",
        "  #fit the model into the data\n",
        "  model.fit(X_train,y_train)\n",
        "  #evaluate the model and append its scoreto model scores\n",
        "  model_scores[name]=model.score(X_test,y_test)\n",
        "return model_scores\n",
        "model_scores = fit_and_score(models,X_train, X_test,y_train, y_test)\n",
        "print(model_scores)"
      ],
      "metadata": {
        "id": "Sm5n1ymp_xf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparison of models"
      ],
      "metadata": {
        "id": "oF6p92DpAcRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_compare =pd.DataFrame(model_scores,index=[\"accuracy\"])\n",
        "model_compare.T.plot.bar();"
      ],
      "metadata": {
        "id": "OCzy_Y_sApoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning our Hyperparameter tuning\n",
        "#feature importance\n",
        "#recall\n",
        "#F1 score\n",
        "#Area under the curve\n",
        "#cross validation\n",
        "#precision\n",
        "#classification report\n",
        "\n",
        "train_scores =[]\n",
        "test_scores =[]\n",
        "# create a list of different values for n_neighbors\n",
        "neighbors = range(1,21)\n",
        "#setup KNN instances\n",
        "knn = KNeighborsClassifier()\n",
        "#loop through different n_neighbors\n",
        "for i in neighbors:\n",
        "  knn.set_params(n_neighbors=i)\n",
        "  #fit the algorithm\n",
        "  knn.fit(X_train,y_train)\n",
        "  #update the training scores\n",
        "  train_scores.append(knn.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "RN9iivXXQxdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning our Hyperparameter tuning\n",
        "#feature importance\n",
        "#recall\n",
        "#F1 score\n",
        "#Area under the curve\n",
        "#cross validation\n",
        "#precision\n",
        "#classification report\n",
        "\n",
        "train_scores =[]\n",
        "test_scores =[]\n",
        "# create a list of different values for n_neighbors\n",
        "neighbors = range(1,21)\n",
        "#setup KNN instances\n",
        "knn = KNeighborsClassifier()\n",
        "#loop through different n_neighbors\n",
        "for i in neighbors:\n",
        "  knn.set_params(n_neighbors=i)\n",
        "  #fit the algorithm\n",
        "  knn.fit(X_train,y_train)\n",
        "  #update the training scores\n",
        "  train_scores.append(knn.score(X_train, y_train)\n",
        "  train_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "oaLpIIbAQ7hD",
        "outputId": "2e292b56-f267-4171-c2a6-b63dae9563b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'(' was never closed (<ipython-input-16-b720fd635d52>, line 22)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-b720fd635d52>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    train_scores.append(knn.score(X_train, y_train)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning with randomizedsearchCV , we are going to tune Logistic regresion and randomforestclassifier"
      ],
      "metadata": {
        "id": "mvYd7UgbSeY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a hyperparamter grid for logistic regression\n",
        "log_reg_grid =(\"C\" : np.logspace(-4,4,20),\"solver\":[\"liblinear\"])\n",
        "#create a hyperparamter grid for RandomForestClassifiers\n",
        "rf_grid ={\"n_estimators\" : np.arrange(10,1000,50),\"max_depth\":[none,3,5,10]\n",
        "          \"min-samples_split\" :np.arrange(2,20,2),\n",
        "          \"min_samples_leaf\":np.arrange(1,20,2)}\n",
        "          #tuning logisticRegression\n",
        "          np.random.seed(42)\n",
        "\n",
        "          #setup Random  hyperparameter search for LogisticRegression\n",
        "          rs_log_reg =RandomizedSearchCV(LogisticRegression(),param_distribution =log_reg_grid,cv=5 ,n_iter =20,verbose=True)\n",
        "          #tuning logistic regression\n",
        "          rs_log_reg.best_params\n",
        "          rs_log_reg.score(X_test,y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J-__Y9M6t_aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "     #tuning RandomForestClassiffier\n",
        "          np.random.seed(42)\n",
        "\n",
        "          #setup Random  hyperparameter search for LogisticRegression\n",
        "          rs_rf=RandomizedSearchCV(RandomForestClassifier(),param_distribution =rf_grid,cv=5 ,n_iter =20,verbose=True)\n",
        "          #tuning logistic regression\n",
        "          rs_rf.fit(X_train,y_train)\n",
        "          #find the best parameters\n",
        "          rs_rf.best_params_\n"
      ],
      "metadata": {
        "id": "why0c-R1BvZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Evaluating our tuned machine learning classifierbeyond accuracy\n",
        "\n",
        "\n",
        "*   ROC curve  and AUC score\n",
        "*  confusion matrix\n",
        "\n",
        "\n",
        "*   Classification report\n",
        "\n",
        "*   precision\n",
        "*  Recall\n",
        "\n",
        "\n",
        "*   F1-score\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dWrcnc8CFueu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions with tuned model\n",
        "y_preds = gs_log_reg.predict(X_test)\n",
        "y_preds\n",
        "#plot ROC curve and calaculate AUC metric\n",
        "plot_roc_curve(gs_log_reg,X_test, y_test)"
      ],
      "metadata": {
        "id": "dCiLl8JHF4Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "print(confusion_matrix(y_test,y_preds))\n",
        "sns.set(font_size=1.5)\n",
        "\n",
        "def plot_conf_mat(y_test, y_preds)\n",
        "fig,ax =plt.subplots(figsize =(3,3))\n",
        "ax =sns.heatmap(confusion_matrix(y_test,y_preds),annot =True,cbar=False)\n",
        "plt.xlabel(\"True label\")\n",
        "plt.ylabel(\"Predicted label\")\n",
        "\n",
        "bottom,top =ax\n",
        "plt.conf_mat(y_test, y_preds)"
      ],
      "metadata": {
        "id": "y1OnrTNAH3bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now getting the classification report as well as cross-validated precision,recall and f-1 score"
      ],
      "metadata": {
        "id": "FHjUDV3KHJjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_preds))"
      ],
      "metadata": {
        "id": "8OIxtrsJHz9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l3Lz6AqNHIrj"
      }
    }
  ]
}